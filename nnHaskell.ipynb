{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diseñar una Red Neuronal usando un lenguaje funcional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la actualidad existen tres argumentos que son usados para interpretar deep learning:\n",
    "\n",
    "- uno basado en las neurociencias que, crea analogías entre las redes neuronales y la **biologia**;\n",
    "- el argumento de **representaciones** usa transformaciones de datos y la **hipótesis de variedades** (manifold hypothesis);\n",
    "- finalmente el enfoque **probabilista**, el cual argumenta que las redes neuronales son similares a encontrar variables latentes.\n",
    "\n",
    "Estos argumentos no son mutuamente exclusivos, pero representan tres maneras diferentes de comprender el deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las representaciones son tipos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada capa de una red neuronal, a los datos se les aplica una transformación, para facilitar la tarea a realizar, \n",
    "estas versiones transformadas de los datos iniciales se les conoce como **representaciones**.\n",
    "Para representar fielmente una red neuronal, en un lenguaje funcional, se asume que las representaciones \n",
    "corresponden a un **tipo**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los **tipos** en ciencias de la computación corresponden a una manera de 'encajar' algún tipo de dato en n bits, similarmente, las representaciones en deep learning corresponden a 'encajar' una **variedad** de datos en n dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la programación funcional dos funciones solo se pueden componer si ambas funciones poseen el mismo *tipo*, \n",
    "dos capas solo se pueden componer cuando la *representación* de los datos corresponde entre sí.\n",
    "Durante el entrenamiento las capas adyacentes negocian la *representación* a usar; el rendimiento de la red depende de que los datos se encuentren en la *representación* que la red espera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check\n",
    "Realizar un mapeo entre distintos tipos de datos hacia la misma representación lleva a realizar tareas complicadas. Por ejemplo, al mapear palabras de distintos lenguajes hacia una representación, es posible encontrar palabras que son traducciones una de otra. Al realizar un mapeo de imagenes y palabras hacia una misma representacion, se puede clasificar las imagenes.\n",
    "![](img/exm1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la programación la abstraccion de funciones, esto reduce masivamente la cantidad de código que se require escribir. \n",
    "Usar multiples copias de una neurona es equivalente a usar funciones. Es claro que no se deben poner neuronas por todo el espacio para que el modelo funcione, se debe explotar las estructuras en los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la practica existen distintos patrones que se usan comúnmente, por ejemplo las redes convolucionales, recurrentes, etc.\n",
    "Estos patrones son equivalentes a funciones de alto orden, esto es, funciones cuyo argumento son otras funciones. Muchos\n",
    "de estos patrones de redes neuronales han sido estudiados extensamente en la programación funcional, de hecho estos \n",
    "corresponden a funciones comunes como **fold**. La única diferencia es que en luagar de recibr como argumento otra función\n",
    "estas funciones reciben un pedazo de red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La instrucción *fold* es equivalente a la codificación, esto es permite tomar una lista de longitud variable como entrada, de una red neuronal recurrente:\n",
    "![](img/RNN-encoding.png)\n",
    "<center><b>fold = Codificar RNN</b></center>\n",
    "<center>Haskell: foldl a s</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para generar una red neuronal recurrente se utiliza la instrucción unfold, así se permite tener una lista como salida:\n",
    "![](img/RNN-generating.png)\n",
    "<center><b>unfold = Generar RNN</b></center>\n",
    "<center>Haskell: unfoldr a s</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las redes neuronales recurrentes en general son mapeos acumulativos:\n",
    "![](img/RNN-general.png)\n",
    "<center><b>mapeo acumulativo = RNN</b></center>\n",
    "<center>Haskell: mapAccumR a s</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "version": "8.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
